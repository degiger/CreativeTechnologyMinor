# CreativeTechnologyMinor - DJ SET "mami tereza"
Doku der Arbeit fÃ¼r Creative Technology von Dario Luciano Giger und Nora-Lee RÃ¼ttimann


# Vlog
https://youtu.be/b5U8JOe641s

# mami tereza â€“ live DJ set mit visuals

## Projektbeschreibung

Im Rahmen des Minors **Creative Technology** haben wir zum ersten Mal mit **TouchDesigner** gearbeitet. Das Tool hat uns direkt fasziniert â€“ besonders die Idee, visuelle Designs zu erstellen, die live auf Musik reagieren. Schnell war klar: Wir wollen ein audioreaktives Visual-Set gestalten.

Zusammen mit der DJane unseres Vertrauens, **mami tereza**, haben wir ein DJ-Set geplant, aufgenommen und mit interaktiven Visuals ergÃ¤nzt. Gemeinsam wurde eine passende Trackliste zusammengestellt, und parallel dazu entwickelten wir visuelle Elemente, die in Echtzeit auf die Musik reagieren.

## Tools & Ressourcen

- [TouchDesigner](https://derivative.ca/)
- [Audacity](https://www.audacityteam.org/)
- YouTube-Tutorials von:
  - [Elekktronaut](https://www.youtube.com/@elekktronaut)
  - [pppanik](https://www.youtube.com/@pppanik)
- UnterstÃ¼tzung durch:
  - **ChatGPT** fÃ¼r technische Hilfe und Debugging

## Einarbeitung & Lernprozess

Da es seitens der Hochschule keine strukturierte EinfÃ¼hrung oder kontinuierliche Betreuung gab, waren wir gezwungen, uns die nÃ¶tigen Kenntnisse eigenstÃ¤ndig anzueignen. Das stellte insbesondere zu Beginn eine groÃŸe Herausforderung dar â€“ zumal uns generell nur sehr wenig Zeit zur VerfÃ¼gung stand und ein hohes MaÃŸ an Eigeninitiative gefordert war.

Die Grundlagen von TouchDesigner konnten wir uns dank zahlreicher YouTube-Tutorials, Online-Foren und ChatGPT schrittweise gut erarbeiten. Deutlich anspruchsvoller war hingegen die technische Umsetzung unserer Ideen, insbesondere ohne Vorerfahrung und ohne die MÃ¶glichkeit, regelmÃ¤ÃŸig auf fachliche UnterstÃ¼tzung zurÃ¼ckzugreifen.

Auch wenn wir den eigenverantwortlichen Lernprozess als bereichernd erlebt haben, hÃ¤tten wir uns punktuell mehr inhaltliche Begleitung gewÃ¼nscht. Eine fundierte EinfÃ¼hrung und gezielter Support hÃ¤tten den Einstieg erleichtert und uns geholfen, schneller zu kreativeren und technisch ausgereifteren Ergebnissen zu gelangen.

## Umsetzung & Technische Herausforderungen

Die VerknÃ¼pfung der Visuals mit Audio-Daten stellte sich als wesentlich komplexer heraus als erwartet. Die Konzeption der Visuals war kreativ spannend, aber die Umsetzung der Reaktion auf Audiofrequenzen â€“ insbesondere durch Snare- und Kick-Detection â€“ erforderte viel technisches VerstÃ¤ndnis und Feintuning.

UrsprÃ¼nglich wollten wir das Set mit CDJs und einem Mixer aufnehmen. Allerdings lieÃŸ sich dieses Audio-Setup nicht wie geplant gleichzeitig mit **Audacity** und **TouchDesigner** verbinden. Daher sind wir kurzfristig auf einen **Controller** umgestiegen. Zwar lieÃŸ sich der Sound so problemlos aufnehmen, doch die ReaktivitÃ¤t der Visuals auf die Musik war dadurch leider eingeschrÃ¤nkt. Die direkte Verbindung zwischen Audio-Input und Visuals hat unter der technischen Limitierung gelitten.

## Ergebnis

Vorort kÃ¼mmerte sich Dario Giger um die Videoaufnahmen, wÃ¤hrend Nora RÃ¼timann Setdesign, Visuals und Projektion Ã¼bernahm. Das Ergebnis ist ein stimmiges audiovisuelles Set, bei dem Bild und Ton auf Ã¤sthetische Weise miteinander verschmelzen â€“ auch wenn es technisch nicht durchgehend so reaktiv wurde wie ursprÃ¼nglich geplant.

## Fazit

Das Projekt war aufwendig, aber extrem lehrreich. Wir haben unsere FÃ¤higkeiten in der kreativen Arbeit mit Echtzeit-Visuals deutlich erweitert und gelernt, mit neuen Tools, unerwarteten Problemen und limitierten Ressourcen umzugehen. Besonders im Bereich der visuellen Gestaltung konnten wir unsere StÃ¤rken einsetzen und weiterentwickeln.

TouchDesigner hat uns gezeigt, wie viel kreatives Potenzial in der Verbindung von Klang und Bild steckt â€“ und wir sind motiviert, diesen Weg weiterzuverfolgen. Trotz aller Stolpersteine sind wir mit dem Resultat sehr zufrieden und stolz auf das, was wir eigenstÃ¤ndig auf die Beine gestellt haben.

---

## ğŸ“ Schritt-fÃ¼r-Schritt-Dokumentation

### 1. ğŸµ Vorbereitung des Audio-Inputs

- Wir haben zu Beginn ein fixes Audiofile verwendet, um unser Setup zu testen.
- WÃ¤hrend des Live-Sets sind wir dann auf ein externes Audio-Device umgestiegen.

![1](https://github.com/user-attachments/assets/e430f880-a935-454b-9e7d-76c245e06005)

---

### 2. ğŸ” Analyse der Audiodaten

Wir haben drei Hauptbereiche zur Analyse des Audiosignals eingerichtet:

- **Kick-Detection**: zur Erkennung der Bassdrums (hohe Pegel).
- **Snare-Detection**: zur Erkennung mittlerer Frequenzimpulse.
- **Speed-Detection**: zur Messung der Geschwindigkeit (Tempo) des Tracks.

#### Aufbau:

- Jeder dieser Bereiche war als eigener Ordner bzw. Subnetz im Node-Netzwerk organisiert.
- Ãœber `In`-Nodes haben wir Daten aus dem Ã¼bergeordneten Node-Baum eingebunden.
- Die Ergebnisse wurden mit `Out`-Nodes zurÃ¼ck ins Hauptnetzwerk gefÃ¼hrt.

![2](https://github.com/user-attachments/assets/908beaef-1d76-4387-85dd-07a36ece78bc)

---

### 3. ğŸš Visuelle Steuerung Ã¼ber Cues

- Wir haben `Cues` definiert, um visuelle AblÃ¤ufe synchron zur Musik zu steuern.
- Beispiel: Die Bewegung von Ballerinas war an den Beat bzw. die Musikgeschwindigkeit gekoppelt.

![3](https://github.com/user-attachments/assets/40426221-b4ec-499d-bd28-92148d89a193)

---

### 4. ğŸŒ€ Umsetzung der Visuals

- Insgesamt haben wir sechs verschiedene Visuals umgesetzt.
- FÃ¼r dynamische Farb- und Bewegungseffekte haben wir intensiv mit **Noise**-Patterns und **Loops** gearbeitet.

![4](https://github.com/user-attachments/assets/e4a027e5-2c86-41d4-af13-9a500ef3541a)


---

### 5. ğŸ© Beispielvisual: Donut mit Text

- Wir haben einen `SOP - Torus` (Donut) als zentrales 3D-Objekt verwendet.
- Darauf wurde ein Textobjekt (z.â€¯B. â€Mami Terezaâ€œ) platziert.
- Licht, Kamera und Animationen wurden integriert und durch Audiosignale gesteuert.

![5](https://github.com/user-attachments/assets/ba10db3f-3a43-4e02-a7e6-710dfc8be0ae)

